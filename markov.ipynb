{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e701bed9-8512-4a8b-b3c8-54c463678b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import re  \n",
    "from time import time \n",
    "from collections import defaultdict\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cefa0048-6500-4136-bf56-443a2be620a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python: No module named spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bb49aa3-b3dc-4b56-9d08-f3bc15787d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "def preprocess_text(text):\n",
    "    if text is None:\n",
    "        return ''\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return tokens\n",
    "    # return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ba650ba-7825-4582-adf6-e4ec62c37574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"ru_core_news_sm\",disable=['ner', 'parser'])\n",
    "# from tqdm import tqdm\n",
    "# def preprocess_text2(text):\n",
    "#     brief_cleaning = [re.sub(\"[^A-Za-zА-Яа-я']+\", ' ', str(row)).lower() for row in text]\n",
    "\n",
    "#     def cleaning(doc):\n",
    "#         txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "#         # return ' '.join(txt)\n",
    "#         return txt\n",
    "#     t = time()\n",
    "#     txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000,n_process=14)]\n",
    "\n",
    "#     print(round((time() - t) / 60, 2))\n",
    "#     return txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b732ec4-e6bc-4cdd-9bab-12f67a769b28",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory (os error 2): ../train_data/automarkup.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2627/867853012.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautomarkup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../train_data/automarkup.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/polars/io/parquet/functions.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(source, columns, n_rows, use_pyarrow, memory_map, storage_options, parallel, row_count_name, row_count_offset, low_memory, pyarrow_options, use_statistics, rechunk)\u001b[0m\n\u001b[1;32m    127\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mpyarrow_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 )\n\u001b[1;32m    129\u001b[0m             )\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         return pl.DataFrame._read_parquet(\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0msource_prep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mn_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/polars/dataframe/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, source, columns, n_rows, parallel, row_count_name, row_count_offset, low_memory, use_statistics, rechunk)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 )\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_projection_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         self._df = PyDataFrame.read_parquet(\n\u001b[0m\u001b[1;32m    863\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0mprojection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory (os error 2): ../train_data/automarkup.parquet"
     ]
    }
   ],
   "source": [
    "automarkup = pl.read_parquet('../train_data/automarkup.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641aa57e-e810-4a7b-9535-77d4f6508136",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =automarkup['query'].to_list()\n",
    "del automarkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2b245-0748-44ff-9d84-0c07b419b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abd4e3-c9dc-4033-b7dd-db5aacc05ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "query[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6d5ebe-3cb6-4f17-93a8-dd8e32801cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_txt = list(map(lambda x: preprocess_text(x),query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb20ad1-48ab-4740-a134-bb1d3e743597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_txt2 = preprocess_text2(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729b871-aa96-4665-97ea-5df34c0ceeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_txt2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a920f06f-5346-44fb-a4a6-9d5775388ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_markov_model_2(txt_list):\n",
    "    markov_model = {}\n",
    "    for req in txt_list:\n",
    "        if len(req) == 0:\n",
    "            continue\n",
    "        current = req[0]\n",
    "        for word in req[1:]:\n",
    "            if current not in markov_model:\n",
    "                markov_model[current] = {}\n",
    "                markov_model[current][word] = 1\n",
    "            else:\n",
    "                if word in markov_model[current]:\n",
    "                    markov_model[current][word] += 1\n",
    "                else:\n",
    "                    markov_model[current][word] = 1\n",
    "            current = word\n",
    "            \n",
    "    \n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count/total\n",
    "        \n",
    "    return markov_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51135b75-eaec-43a8-9e4f-6b5d3d73bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_markov_model_2(preprocess_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8a73c-6661-4f10-a2ba-39218234b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 =make_markov_model_2(preprocess_txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be64aee-b28c-4b74-beab-d812ef4d0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_supp(markov_model, limit=100, start='my god'):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story+=curr_state+\" \"\n",
    "    while n<limit:\n",
    "        if curr_state not in markov_model:\n",
    "            break\n",
    "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
    "                                    list(markov_model[curr_state].values()))\n",
    "        \n",
    "        curr_state = next_state[0]\n",
    "        story+=curr_state+\" \"\n",
    "        n+=1\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd4a6e-6f6e-4053-82c3-a43d0fe1433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    # print(str(i)+\". \", generate_supp(model1, start=\"рецепт\", limit=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d543e23-709c-41f3-b304-629dc790befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_supp(model, start=\"рецепт\", limit=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd1218-224b-4bef-8d17-98d9bc836e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def generate_supp3(markov_model, start, now=0, limit=10, result=None):\n",
    "    if result is None:\n",
    "        result =start +' '\n",
    "    if now>= limit:\n",
    "        return [result]\n",
    "    if start not in markov_model:\n",
    "        return [result]\n",
    "    next_state = sorted(list(markov_model[start].keys()), key=lambda x: markov_model[start][x],reverse=True)\n",
    "    sum_result=[]\n",
    "    max_n=2\n",
    "    for n,i in enumerate(next_state):\n",
    "        if i in result:\n",
    "            max_n+=1\n",
    "            continue \n",
    "            \n",
    "        sum_result+=generate_supp3(markov_model,i, now+1,limit, result + i+' ')\n",
    "        if n>=max_n:\n",
    "            break\n",
    "        \n",
    "    return sum_result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec00927-3653-4914-8c71-379b4ce0c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_supp3(model,'рецепт',limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99ccea-fd66-4a29-9ba0-45db468239dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_supp3(model1,'рецепт',limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb563e6-24b8-456e-8668-3984469bab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_supp4(markov_model, limit=100, start='my god'):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story+=curr_state+\" \"\n",
    "    while n<limit:\n",
    "        if curr_state not in markov_model:\n",
    "            break\n",
    "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
    "                                    list(map(lambda x: x**2,markov_model[curr_state].values())))\n",
    "        \n",
    "        curr_state = next_state[0]\n",
    "        story+=curr_state+\" \"\n",
    "        n+=1\n",
    "    return story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1abb9-b95a-4e5c-9f12-9e285f669fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_supp4(model, start=\"рецепт\", limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda55e8-94d4-4d7e-8526-7b6b6aa405e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(20):\n",
    "    print(str(i)+\". \", generate_supp4(model1, start=\"рецепт\", limit=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70edd63-455d-4377-85df-731b2258c739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
