{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from faiss import write_index, read_index\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"inkoziev/sbert_pq\", device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_t = pl.read_parquet('../train_data/videos.parquet',columns=['video_title']).select(pl.col('video_title').str.to_lowercase())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = videos_t['video_title'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "batch_size = 200000\n",
    "num_batches = math.ceil(len(corpus) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from faiss import write_index, read_index\n",
    "faiss.omp_get_max_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 312\n",
    "cpu_index = faiss.IndexFlatL2(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = faiss.StandardGpuResources()  # use a single GPU\n",
    "# gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, cpu_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    if True:\n",
    "        try:\n",
    "            for i in range(num_batches):\n",
    "                # формируем батч\n",
    "                start, end = i * batch_size, (i + 1) * batch_size\n",
    "                corpus_batch = corpus[start:end]\n",
    "\n",
    "                # считаем вектора для всех предложений в батче\n",
    "                embeddings = model.encode(\n",
    "                    corpus_batch,\n",
    "                    batch_size=40000,\n",
    "                    show_progress_bar=True\n",
    "                )\n",
    "\n",
    "                # добавляем новые батч векторов в индекс и сохраняем его\n",
    "                cpu_index.add(embeddings)\n",
    "\n",
    "                if i%10==0:\n",
    "                    write_index(cpu_index, 'candidates.index')\n",
    "\n",
    "\n",
    "                print(f'batch: {i + 1} / {num_batches}, vectors: {cpu_index.ntotal}')\n",
    "\n",
    "                del embeddings\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "        except KeyboardInterrupt:\n",
    "            print('Остановлено пользователем')\n",
    "            try:\n",
    "                del embeddings\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu_index = faiss.index_gpu_to_cpu(gpu_index_flat)  # error happens here\n",
    "write_index(cpu_index, 'candidates.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4049710,
     "sourceId": 7038953,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
