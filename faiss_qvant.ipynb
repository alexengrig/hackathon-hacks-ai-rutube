{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-24T03:46:44.930319Z","iopub.execute_input":"2023-11-24T03:46:44.930697Z","iopub.status.idle":"2023-11-24T03:46:46.436285Z","shell.execute_reply.started":"2023-11-24T03:46:44.930651Z","shell.execute_reply":"2023-11-24T03:46:46.435322Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# !pip install sentence_transformers\n# !pip install faiss-gpu ","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:46:46.441220Z","iopub.execute_input":"2023-11-24T03:46:46.441494Z","iopub.status.idle":"2023-11-24T03:46:46.445461Z","shell.execute_reply.started":"2023-11-24T03:46:46.441469Z","shell.execute_reply":"2023-11-24T03:46:46.444518Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nsentences = [\"Кошка ловит мышку\", \"Each sentence is converted\"]\n\n\nfrom sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer(\"inkoziev/sbert_pq\", device='cuda')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:46:46.446834Z","iopub.execute_input":"2023-11-24T03:46:46.447609Z","iopub.status.idle":"2023-11-24T03:46:49.022474Z","shell.execute_reply.started":"2023-11-24T03:46:46.447549Z","shell.execute_reply":"2023-11-24T03:46:49.021688Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls ../input/data-pkldir/","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:46:49.024809Z","iopub.execute_input":"2023-11-24T03:46:49.025236Z","iopub.status.idle":"2023-11-24T03:46:49.990651Z","shell.execute_reply.started":"2023-11-24T03:46:49.025209Z","shell.execute_reply":"2023-11-24T03:46:49.989375Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"data.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\nwith open('../input/data-pkldir/data.pkl', 'rb') as fp:\n    corpus = pickle.load(fp)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:46:49.992198Z","iopub.execute_input":"2023-11-24T03:46:49.992577Z","iopub.status.idle":"2023-11-24T03:47:05.602447Z","shell.execute_reply.started":"2023-11-24T03:46:49.992529Z","shell.execute_reply":"2023-11-24T03:47:05.601605Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import math\nbatch_size = 100000\nnum_batches = math.ceil(len(corpus) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:47:05.603759Z","iopub.execute_input":"2023-11-24T03:47:05.604114Z","iopub.status.idle":"2023-11-24T03:47:05.609144Z","shell.execute_reply.started":"2023-11-24T03:47:05.604083Z","shell.execute_reply":"2023-11-24T03:47:05.608343Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"num_batches","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:47:58.607167Z","iopub.execute_input":"2023-11-24T03:47:58.607525Z","iopub.status.idle":"2023-11-24T03:47:58.613818Z","shell.execute_reply.started":"2023-11-24T03:47:58.607496Z","shell.execute_reply":"2023-11-24T03:47:58.612843Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"345"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:47:05.610477Z","iopub.execute_input":"2023-11-24T03:47:05.610831Z","iopub.status.idle":"2023-11-24T03:47:06.617846Z","shell.execute_reply.started":"2023-11-24T03:47:05.610800Z","shell.execute_reply":"2023-11-24T03:47:06.616828Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"37"},"metadata":{}}]},{"cell_type":"code","source":"import faiss\nfrom faiss import write_index, read_index","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:47:06.619020Z","iopub.execute_input":"2023-11-24T03:47:06.619372Z","iopub.status.idle":"2023-11-24T03:47:06.656654Z","shell.execute_reply.started":"2023-11-24T03:47:06.619345Z","shell.execute_reply":"2023-11-24T03:47:06.655807Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"d = 312\ncpu_index = faiss.index_factory(d, \"IVF100,PQ8\")\ncpu_index.is_trained, cpu_index.ntotal\nres = faiss.StandardGpuResources()  # use a single GPU\n\n## Using a flat index\n\n\n# make it a flat GPU index\ngpu_index_flat = faiss.index_cpu_to_gpu(res, 0, cpu_index)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:47:06.657759Z","iopub.execute_input":"2023-11-24T03:47:06.658046Z","iopub.status.idle":"2023-11-24T03:47:07.390903Z","shell.execute_reply.started":"2023-11-24T03:47:06.658021Z","shell.execute_reply":"2023-11-24T03:47:07.390071Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model.eval()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T03:47:07.391993Z","iopub.execute_input":"2023-11-24T03:47:07.392294Z","iopub.status.idle":"2023-11-24T03:47:07.399526Z","shell.execute_reply.started":"2023-11-24T03:47:07.392268Z","shell.execute_reply":"2023-11-24T03:47:07.398544Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"SentenceTransformer(\n  (0): Transformer({'max_seq_length': 2048, 'do_lower_case': False}) with Transformer model: BertModel \n  (1): Pooling({'word_embedding_dimension': 312, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n)"},"metadata":{}}]},{"cell_type":"code","source":"with torch.no_grad():\n    if True:\n        try:\n            for i in range(0,200):\n                # формируем батч\n                start, end = i * batch_size, (i + 1) * batch_size\n                corpus_batch = corpus[start:end]\n\n                # считаем вектора для всех предложений в батче\n                embeddings = model.encode(\n                    corpus_batch,\n                    batch_size=5000,\n                    show_progress_bar=True\n                )\n\n                # добавляем новые батч векторов в индекс и сохраняем его\n                gpu_index_flat.train(embeddings)\n\n\n                print(f'batch: {i + 1} / {num_batches}, vectors: {cpu_index.ntotal}')\n\n                # чистим ОЗУ\n                del embeddings\n                gc.collect()\n                torch.cuda.empty_cache()\n        except KeyboardInterrupt:\n            print('Остановлено пользователем')\n            try:\n                del embeddings\n            except:\n                pass","metadata":{"execution":{"iopub.status.idle":"2023-11-24T05:01:06.255600Z","shell.execute_reply.started":"2023-11-24T04:28:44.720962Z","shell.execute_reply":"2023-11-24T05:01:06.254629Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"batch: 175 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30c56941929842b2aec1fdde54e589d2"}},"metadata":{}},{"name":"stdout","text":"batch: 176 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"206de0909efe43da8d535ac1023f9750"}},"metadata":{}},{"name":"stdout","text":"batch: 177 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a6a328db37648c88b6baf92c17c0ac7"}},"metadata":{}},{"name":"stdout","text":"batch: 178 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdd33fabe5084520bf0c1a5080683e88"}},"metadata":{}},{"name":"stdout","text":"batch: 179 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61edf14dd0794ba483063be8efb4d76a"}},"metadata":{}},{"name":"stdout","text":"batch: 180 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c46255e88b24b919b750209af217046"}},"metadata":{}},{"name":"stdout","text":"batch: 181 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b230914e7834ee4bdd9c0581c7aa068"}},"metadata":{}},{"name":"stdout","text":"batch: 182 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47b656bf4e16475bb6481a195d1ab879"}},"metadata":{}},{"name":"stdout","text":"batch: 183 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac52ded180cd4df5b9a3d17b7bc7c4b3"}},"metadata":{}},{"name":"stdout","text":"batch: 184 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7d9ad981b6846ecaff3db86fe85eec4"}},"metadata":{}},{"name":"stdout","text":"batch: 185 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3703c451e0524c5bb6894d45dc615e8a"}},"metadata":{}},{"name":"stdout","text":"batch: 186 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f83ba82503643bbb42033c04ddb7c24"}},"metadata":{}},{"name":"stdout","text":"batch: 187 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20212e8e2e414f03a1fab4a10bf040c3"}},"metadata":{}},{"name":"stdout","text":"batch: 188 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c522a86c58c47afb38cb1012034cc4a"}},"metadata":{}},{"name":"stdout","text":"batch: 189 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d846dfe1caa463d8c13745bdbadf9cf"}},"metadata":{}},{"name":"stdout","text":"batch: 190 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c8e7694756f4756a0fca36eca3f94d5"}},"metadata":{}},{"name":"stdout","text":"batch: 191 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bb1675b12754d76b2fccd1c23d3dbf1"}},"metadata":{}},{"name":"stdout","text":"batch: 192 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be33557b712b48d98a673be473c0fe1a"}},"metadata":{}},{"name":"stdout","text":"batch: 193 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a89e39ab3ef4933bfa0ad1f273709b7"}},"metadata":{}},{"name":"stdout","text":"batch: 194 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d33ce33c0b604eb4926aad2b19421de6"}},"metadata":{}},{"name":"stdout","text":"batch: 195 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2660a21381a8473e847273f29ac80e30"}},"metadata":{}},{"name":"stdout","text":"batch: 196 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0b075077cd34141a8fa9a8f736ccccf"}},"metadata":{}},{"name":"stdout","text":"batch: 197 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca2bd9d252514288a1ac1c54dbe81642"}},"metadata":{}},{"name":"stdout","text":"batch: 198 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbb5645b27684df4a990bd8360827e0f"}},"metadata":{}},{"name":"stdout","text":"batch: 199 / 345, vectors: 0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"622d3f4b6b904f5bb4e53e79aea8b4be"}},"metadata":{}},{"name":"stdout","text":"batch: 200 / 345, vectors: 0\n","output_type":"stream"}]},{"cell_type":"code","source":"cpu_index.is_trained, cpu_index.ntotal","metadata":{"execution":{"iopub.status.busy":"2023-11-24T04:10:32.069709Z","iopub.execute_input":"2023-11-24T04:10:32.070483Z","iopub.status.idle":"2023-11-24T04:10:32.077046Z","shell.execute_reply.started":"2023-11-24T04:10:32.070451Z","shell.execute_reply":"2023-11-24T04:10:32.076047Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(False, 0)"},"metadata":{}}]},{"cell_type":"code","source":"gpu_index_flat.is_trained, gpu_index_flat.ntotal\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T04:10:49.051641Z","iopub.execute_input":"2023-11-24T04:10:49.052010Z","iopub.status.idle":"2023-11-24T04:10:49.058473Z","shell.execute_reply.started":"2023-11-24T04:10:49.051980Z","shell.execute_reply":"2023-11-24T04:10:49.057487Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(True, 0)"},"metadata":{}}]},{"cell_type":"code","source":"\n# co = faiss.GpuClonerOptions()\n# co.useFloat16 = True\n# # co.usePrecomputed = False\n# co.indicesOptions = faiss.INDICES_CPU\n\n# res = faiss.StandardGpuResources()\n\ncpu_index = faiss.index_gpu_to_cpu(gpu_index_flat)  # error happens here\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:01:31.103520Z","iopub.execute_input":"2023-11-24T05:01:31.104235Z","iopub.status.idle":"2023-11-24T05:01:31.108788Z","shell.execute_reply.started":"2023-11-24T05:01:31.104200Z","shell.execute_reply":"2023-11-24T05:01:31.107862Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"cpu_index.is_trained, cpu_index.ntotal","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:01:35.967425Z","iopub.execute_input":"2023-11-24T05:01:35.968353Z","iopub.status.idle":"2023-11-24T05:01:35.974335Z","shell.execute_reply.started":"2023-11-24T05:01:35.968314Z","shell.execute_reply":"2023-11-24T05:01:35.973442Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(True, 0)"},"metadata":{}}]},{"cell_type":"code","source":"write_index(cpu_index, 'candidates.index')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:02:04.863973Z","iopub.execute_input":"2023-11-24T05:02:04.864851Z","iopub.status.idle":"2023-11-24T05:02:04.868954Z","shell.execute_reply.started":"2023-11-24T05:02:04.864818Z","shell.execute_reply":"2023-11-24T05:02:04.868002Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"!ls -l","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:02:10.461066Z","iopub.execute_input":"2023-11-24T05:02:10.461798Z","iopub.status.idle":"2023-11-24T05:02:11.645579Z","shell.execute_reply.started":"2023-11-24T05:02:10.461767Z","shell.execute_reply":"2023-11-24T05:02:11.644506Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"total 436\n-rw-r--r-- 1 root root 444468 Nov 24 05:02 candidates.index\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls -l","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:09:18.782317Z","iopub.execute_input":"2023-11-24T05:09:18.782692Z","iopub.status.idle":"2023-11-24T05:09:19.958967Z","shell.execute_reply.started":"2023-11-24T05:09:18.782664Z","shell.execute_reply":"2023-11-24T05:09:19.957739Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"total 31688\n-rw-r--r-- 1 root root 32445268 Nov 24 05:09 candidates.index\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_methods(object, spacing=20):\n  methodList = []\n  for method_name in dir(object):\n    try:\n        if callable(getattr(object, method_name)):\n            methodList.append(str(method_name))\n    except Exception:\n        methodList.append(str(method_name))\n  processFunc = (lambda s: ' '.join(s.split())) or (lambda s: s)\n  for method in methodList:\n    try:\n        print(str(method.ljust(spacing)) + ' ' +\n              processFunc(str(getattr(object, method).__doc__)[0:90]))\n    except Exception:\n        print(method.ljust(spacing) + ' ' + ' getattr() failed')\n\nget_methods(gpu_index_flat)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T04:08:05.070506Z","iopub.execute_input":"2023-11-24T04:08:05.070928Z","iopub.status.idle":"2023-11-24T04:08:05.079620Z","shell.execute_reply.started":"2023-11-24T04:08:05.070889Z","shell.execute_reply":"2023-11-24T04:08:05.078707Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"__class__            IVFPQ index for the GPU\n__delattr__          Implement delattr(self, name).\n__dir__              Default dir() implementation.\n__eq__               Return self==value.\n__format__           Default object formatter.\n__ge__               Return self>=value.\n__getattribute__     Return getattr(self, name).\n__getstate__         None\n__gt__               Return self>value.\n__hash__             Return hash(self).\n__init__             *Overload 1:* Construct from a pre-existing faiss::IndexIVFPQ instance, c\n__init_subclass__    This method is called when a class is subclassed. The default implementation does nothing\n__le__               Return self<=value.\n__lt__               Return self<value.\n__ne__               Return self!=value.\n__new__              Create and return a new object. See help(type) for accurate signature.\n__reduce__           Helper for pickle.\n__reduce_ex__        Helper for pickle.\n__repr__             None\n__setattr__          Implement setattr(self, name, value).\n__setstate__         None\n__sizeof__           Size of object in memory, in bytes.\n__str__              Return str(self).\n__subclasshook__     Abstract classes can override this to customize issubclass(). This is invoked early on by\n__swig_destroy__     None\nadd                  Adds vectors to the index. The index must be trained before vectors can be added t\nadd_c                `x` can be resident on the CPU or any GPU; copies are performed as needed\nadd_with_ids         Adds vectors with arbitrary ids to the index (not all indexes support this). The i\nadd_with_ids_c       `x` and `ids` can be resident on the CPU or any GPU; copies are performed\nassign               Find the k nearest neighbors of the set of vectors x in the index. This is the sam\nassign_c             `x` and `labels` can be resident on the CPU or any GPU; copies are perfor\ncompute_residual     Overridden to force GPU indices to provide their own GPU-friendly impleme\ncompute_residual_n   Overridden to force GPU indices to provide their own GPU-friendly impleme\ncopyFrom             Reserve space on the GPU for the inverted lists for `num` vectors, assume\ncopyTo               Copy ourselves to the given CPU index; will overwrite all data in the ind\ngetBitsPerCode       Return the number of bits per PQ code\ngetCentroidsPerSubQuantizer Return the number of centroids per PQ code (2^bits per code)\ngetDevice            Returns the device that this index is resident on\ngetListIndices       Return the vector indices contained in a particular inverted list, for de\ngetListLength        Returns the number of vectors present in a particular inverted list\ngetListVectorData    Return the encoded vector data contained in a particular inverted list, f\ngetMinPagingSize     Returns the current minimum data size for paged searches\ngetNumLists          Returns the number of inverted lists we're managing\ngetNumProbes         Returns our current number of list probes per query\ngetNumSubQuantizers  Return the number of sub-quantizers we are using\ngetPrecomputedCodes  Are pre-computed codes enabled?\ngetQuantizer         Return the quantizer we're using\ngetResources         Returns a reference to our GpuResources object that manages memory, strea\nget_distance_computer Get a DistanceComputer (defined in AuxIndexStructures) object for this k\nrange_search         Search vectors that are within a distance of the query vectors. Parameters\nrange_search_c       query n vectors of dimension d to the index. return all vectors with di\nreclaimMemory        After adding vectors, one can call this to reclaim device memory to exact\nreconstruct          Approximate reconstruction of one vector from the index. Parameters -----\nreconstruct_c        Reconstruct a stored vector (or an approximation if lossy coding) this\nreconstruct_n        Approximate reconstruction of vectors `n0` ... `n0 + ni - 1` from the index. Missi\nreconstruct_n_c      Reconstruct vectors i0 to i0 + ni - 1 this function may not be defined\nremove_ids           Remove some ids from the index. This is a O(ntotal) operation by default, so could\nremove_ids_c         removes IDs from the index. Not supported by all indexes. Returns the nu\nreserveMemory        Reserve GPU memory in our inverted lists for this number of vectors\nreset                Clears out all inverted lists, but retains the coarse and product centroi\nsa_code_size         size of the produced codes in bytes\nsa_decode            None\nsa_decode_c          encode a set of vectors :type n: int :param n: number of\nsa_encode            None\nsa_encode_c          encode a set of vectors :type n: int :param n: number of\nsearch               Find the k nearest neighbors of the set of vectors x in the index. Parameters\nsearch_and_reconstruct Find the k nearest neighbors of the set of vectors x in the index, and return an a\nsearch_and_reconstruct_c Similar to search, but also reconstructs the stored vectors (or an appro\nsearch_c             `x`, `distances` and `labels` can be resident on the CPU or any GPU; copi\nsetMinPagingSize     Set the minimum data size for searches (in MiB) for which we use CPU -> G\nsetNumProbes         Sets the number of list probes per query\nsetPrecomputedCodes  Enable or disable pre-computed codes\ntrain                Trains the index on a representative set of vectors. The index must be trained bef\ntrain_c              Trains the coarse and product quantizer based on the given vector data\n","output_type":"stream"}]},{"cell_type":"code","source":"get_methods(cpu_index)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T04:08:35.368592Z","iopub.execute_input":"2023-11-24T04:08:35.369537Z","iopub.status.idle":"2023-11-24T04:08:35.375338Z","shell.execute_reply.started":"2023-11-24T04:08:35.369503Z","shell.execute_reply":"2023-11-24T04:08:35.374204Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"__class__            Inverted file with Product Quantizer encoding. Each residual vector is encoded a\n__delattr__          Implement delattr(self, name).\n__dir__              Default dir() implementation.\n__eq__               Return self==value.\n__format__           Default object formatter.\n__ge__               Return self>=value.\n__getattribute__     Return getattr(self, name).\n__getstate__         None\n__gt__               Return self>value.\n__hash__             Return hash(self).\n__init__             None\n__init_subclass__    This method is called when a class is subclassed. The default implementation does nothing\n__le__               Return self<=value.\n__lt__               Return self<value.\n__ne__               Return self!=value.\n__new__              Create and return a new object. See help(type) for accurate signature.\n__reduce__           Helper for pickle.\n__reduce_ex__        Helper for pickle.\n__repr__             None\n__setattr__          Implement setattr(self, name, value).\n__setstate__         None\n__sizeof__           Size of object in memory, in bytes.\n__str__              Return str(self).\n__subclasshook__     Abstract classes can override this to customize issubclass(). This is invoked early on by\n__swig_destroy__     None\nadd                  Adds vectors to the index. The index must be trained before vectors can be added t\nadd_c                Calls add_with_ids with NULL ids\nadd_core             None\nadd_core_o           same as add_core, also: - output 2nd level residuals if residuals_2 != NU\nadd_sa_codes         None\nadd_sa_codes_c       Add vectors that are computed with the standalone codec :type codes: ui\nadd_with_ids         Adds vectors with arbitrary ids to the index (not all indexes support this). The i\nadd_with_ids_c       default implementation that calls encode_vectors\nassign               Find the k nearest neighbors of the set of vectors x in the index. This is the sam\nassign_c             return the indexes of the k vectors closest to the query x. This functi\ncheck_compatible_for_merge check that the two indexes are compatible (ie, they are trained in the s\ncoarse_code_size     compute the number of bytes required to store list ids\ncompute_residual     Computes a residual vector after indexing encoding. The residual vector\ncompute_residual_n   Computes a residual vector after indexing encoding (batch form). Equival\ncopy_subset_to       copy a subset of the entries index to the other index if subset_type ==\ndecode_listno        None\ndecode_multiple      inverse of encode_multiple\nencode               None\nencode_listno        None\nencode_multiple      Encode multiple vectors :type n: int :param n: nb vectors\nencode_vectors       None\nfind_duplicates      Find exact duplicates in the dataset. the duplicates are returned in pr\nget_InvertedListScanner None\nget_distance_computer Get a DistanceComputer (defined in AuxIndexStructures) object for this k\nget_list_size        None\nmake_direct_map      intialize a direct map :type new_maintain_direct_map: boolean, optional\nmerge_from           moves the entries from another dataset to self. On output, other is empt\nprecompute_table     build precomputed table\nrange_search         Search vectors that are within a distance of the query vectors. Parameters\nrange_search_c       None\nrange_search_preassigned None\nreconstruct          Approximate reconstruction of one vector from the index. Parameters -----\nreconstruct_c        reconstruct a vector. Works only if maintain_direct_map is set to 1 or 2\nreconstruct_from_offset None\nreconstruct_n        Approximate reconstruction of vectors `n0` ... `n0 + ni - 1` from the index. Missi\nreconstruct_n_c      Reconstruct a subset of the indexed vectors. Overrides default implemen\nremove_ids           Remove some ids from the index. This is a O(ntotal) operation by default, so could\nremove_ids_c         Dataset manipulation functions\nreplace_invlists     replace the inverted lists, old one is deallocated if own_invlists\nreset                None\nsa_code_size         None\nsa_decode            None\nsa_decode_c          None\nsa_encode            None\nsa_encode_c          None\nsearch               Find the k nearest neighbors of the set of vectors x in the index. Parameters\nsearch_and_reconstruct Find the k nearest neighbors of the set of vectors x in the index, and return an a\nsearch_and_reconstruct_c Similar to search, but also reconstructs the stored vectors (or an appro\nsearch_c             assign the vectors, then call search_preassign\nsearch_preassigned   search a set of vectors, that are pre-quantized by the IVF quantizer. F\nset_direct_map_type  None\ntrain                Trains the index on a representative set of vectors. The index must be trained bef\ntrain_c              Trains the quantizer and calls train_residual to train sub-quantizers\ntrain_q1             Trains the quantizer and calls train_residual to train sub-quantizers\ntrain_residual       trains the product quantizer\ntrain_residual_o     same as train_residual, also output 2nd level residuals\nupdate_vectors       None\nupdate_vectors_c     Update a subset of vectors. The index must have a direct_map :\n","output_type":"stream"}]},{"cell_type":"code","source":"del gpu_index_flat","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:17:57.622372Z","iopub.execute_input":"2023-11-24T05:17:57.623273Z","iopub.status.idle":"2023-11-24T05:17:58.706000Z","shell.execute_reply.started":"2023-11-24T05:17:57.623237Z","shell.execute_reply":"2023-11-24T05:17:58.704897Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:17:58.707261Z","iopub.execute_input":"2023-11-24T05:17:58.707758Z","iopub.status.idle":"2023-11-24T05:17:59.815717Z","shell.execute_reply.started":"2023-11-24T05:17:58.707726Z","shell.execute_reply":"2023-11-24T05:17:59.814532Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    if True:\n        try:\n            for i in range(40,100):\n                # формируем батч\n                start, end = i * batch_size, (i + 1) * batch_size\n                corpus_batch = corpus[start:end]\n\n                # считаем вектора для всех предложений в батче\n                embeddings = model.encode(\n                    corpus_batch,\n                    batch_size=5000,\n                    show_progress_bar=True\n                )\n\n                # добавляем новые батч векторов в индекс и сохраняем его\n                cpu_index.add(embeddings)\n                write_index(cpu_index, 'candidates.index')\n\n                print(f'batch: {i + 1} / {num_batches}, vectors: {cpu_index.ntotal}')\n\n                # чистим ОЗУ\n                del embeddings\n                gc.collect()\n                torch.cuda.empty_cache()\n        except KeyboardInterrupt:\n            print('Остановлено пользователем')\n            try:\n                del embeddings\n            except:\n                pass","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:18:24.702031Z","iopub.execute_input":"2023-11-24T05:18:24.702422Z","iopub.status.idle":"2023-11-24T05:38:47.628943Z","shell.execute_reply.started":"2023-11-24T05:18:24.702389Z","shell.execute_reply":"2023-11-24T05:38:47.627633Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03965e3390eb42c2936642e103cacac0"}},"metadata":{}},{"name":"stdout","text":"batch: 41 / 345, vectors: 4100000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f8c2a3969044a859c7c455de0cb3f13"}},"metadata":{}},{"name":"stdout","text":"batch: 42 / 345, vectors: 4200000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c5cd0f16b184cb78be697fc5279ecab"}},"metadata":{}},{"name":"stdout","text":"batch: 43 / 345, vectors: 4300000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bca15d09a8384589a3717ca01b86a34b"}},"metadata":{}},{"name":"stdout","text":"batch: 44 / 345, vectors: 4400000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4939ff079f134bf899c9799b25ad716c"}},"metadata":{}},{"name":"stdout","text":"batch: 45 / 345, vectors: 4500000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7701fcd8f23445f0bf9d2118dbee7c8e"}},"metadata":{}},{"name":"stdout","text":"batch: 46 / 345, vectors: 4600000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3cd7774047342078844f3f8ea3fb673"}},"metadata":{}},{"name":"stdout","text":"batch: 47 / 345, vectors: 4700000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cab2ac5e10941e6b542b30263bd53a1"}},"metadata":{}},{"name":"stdout","text":"batch: 48 / 345, vectors: 4800000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"362889bc636449d9b6d15daacb5e2f9b"}},"metadata":{}},{"name":"stdout","text":"batch: 49 / 345, vectors: 4900000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce561c28deec4586aff200760c612c87"}},"metadata":{}},{"name":"stdout","text":"batch: 50 / 345, vectors: 5000000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"950a84715e7642ec981923320bed0782"}},"metadata":{}},{"name":"stdout","text":"batch: 51 / 345, vectors: 5100000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c25e103fbd548f1a7952b2d4ab908c0"}},"metadata":{}},{"name":"stdout","text":"batch: 52 / 345, vectors: 5200000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a772aca32c94e3da1ef033171424966"}},"metadata":{}},{"name":"stdout","text":"batch: 53 / 345, vectors: 5300000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"773a3ed4c9744527b013c78f173f884d"}},"metadata":{}},{"name":"stdout","text":"batch: 54 / 345, vectors: 5400000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eceeab9e84784bbc907a9f6ea75675d7"}},"metadata":{}},{"name":"stdout","text":"batch: 55 / 345, vectors: 5500000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a7e8f404410418bb4e5aadd3be55630"}},"metadata":{}},{"name":"stdout","text":"batch: 56 / 345, vectors: 5600000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f88e11dabec44924b182d88768488d5c"}},"metadata":{}},{"name":"stdout","text":"batch: 57 / 345, vectors: 5700000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01150f1124ac40acb0950cdf11175262"}},"metadata":{}},{"name":"stdout","text":"batch: 58 / 345, vectors: 5800000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dd828dd492a4e2db848bad5c9f14b30"}},"metadata":{}},{"name":"stdout","text":"batch: 59 / 345, vectors: 5900000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c46facbd726944f7b1e7255a07eaec2a"}},"metadata":{}},{"name":"stdout","text":"batch: 60 / 345, vectors: 6000000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a2db4d4986f4c7d946115a775fd983b"}},"metadata":{}},{"name":"stdout","text":"batch: 61 / 345, vectors: 6100000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"169cd86f90454be4bb48b34805d64a65"}},"metadata":{}},{"name":"stdout","text":"batch: 62 / 345, vectors: 6200000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dc1ef7003e24c54a08f529b6088ce2a"}},"metadata":{}},{"name":"stdout","text":"batch: 63 / 345, vectors: 6300000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6584dcec83294b4f82f1e2d045d16fb3"}},"metadata":{}},{"name":"stdout","text":"batch: 64 / 345, vectors: 6400000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76d4cb18fa5e45658923224b7724b54e"}},"metadata":{}},{"name":"stdout","text":"batch: 65 / 345, vectors: 6500000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1daf8cdf9d81451c9825104c3a2ce553"}},"metadata":{}},{"name":"stdout","text":"batch: 66 / 345, vectors: 6600000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7aa87386bae44b8bc6e3e25eed9b877"}},"metadata":{}},{"name":"stdout","text":"batch: 67 / 345, vectors: 6700000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77fc4e78172d474caa5e043f70c62fd1"}},"metadata":{}},{"name":"stdout","text":"batch: 68 / 345, vectors: 6800000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ecc9a25fab845bb8f6f9e70f98f6238"}},"metadata":{}},{"name":"stdout","text":"batch: 69 / 345, vectors: 6900000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5e67ab231604b8f9578768e57e19a53"}},"metadata":{}},{"name":"stdout","text":"batch: 70 / 345, vectors: 7000000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a29d01f94fa4096996967abd6619f5d"}},"metadata":{}},{"name":"stdout","text":"batch: 71 / 345, vectors: 7100000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de76c148c17e4237af2d4223095aa7c7"}},"metadata":{}},{"name":"stdout","text":"batch: 72 / 345, vectors: 7200000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2da76d3e95a424aa8fc96b8ff4a9843"}},"metadata":{}},{"name":"stdout","text":"batch: 73 / 345, vectors: 7300000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"505847c00bd945eea7049c667e2ad476"}},"metadata":{}},{"name":"stdout","text":"batch: 74 / 345, vectors: 7400000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"993bb31d8420403ca2c8310b7ea8f398"}},"metadata":{}},{"name":"stdout","text":"batch: 75 / 345, vectors: 7500000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6aaa7d9eeb841bf8b4bda38e135c783"}},"metadata":{}},{"name":"stdout","text":"batch: 76 / 345, vectors: 7600000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5097e72592074df6bb736d40402fde30"}},"metadata":{}},{"name":"stdout","text":"batch: 77 / 345, vectors: 7700000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d036c92f3aa341f9b3da844909c247b9"}},"metadata":{}},{"name":"stdout","text":"batch: 78 / 345, vectors: 7800000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0934606dbe75478da056312472fb9c7b"}},"metadata":{}},{"name":"stdout","text":"batch: 79 / 345, vectors: 7900000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8da6a5a401f443f787a71580dacb17f0"}},"metadata":{}},{"name":"stdout","text":"batch: 80 / 345, vectors: 8000000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19f6b898d7e2474fbb0c206cb3927a7f"}},"metadata":{}},{"name":"stdout","text":"batch: 81 / 345, vectors: 8100000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b41265c9f458487984f152ff6f197331"}},"metadata":{}},{"name":"stdout","text":"batch: 82 / 345, vectors: 8200000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d199075cc1e46f4aeea21d8851c9f52"}},"metadata":{}},{"name":"stdout","text":"batch: 83 / 345, vectors: 8300000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d91f335e80a4944af1eb87b1c062d48"}},"metadata":{}},{"name":"stdout","text":"batch: 84 / 345, vectors: 8400000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2c2a164d6b14f42a6427e5c963e87c9"}},"metadata":{}},{"name":"stdout","text":"batch: 85 / 345, vectors: 8500000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c19b6a7767014bb88232853b3991e0ff"}},"metadata":{}},{"name":"stdout","text":"batch: 86 / 345, vectors: 8600000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f138088c83840ba95cbc905ea6b29db"}},"metadata":{}},{"name":"stdout","text":"batch: 87 / 345, vectors: 8700000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e308b873d37488788bcae79d5152f9b"}},"metadata":{}},{"name":"stdout","text":"batch: 88 / 345, vectors: 8800000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dd107a3a46641dbb82bc649911b3d05"}},"metadata":{}},{"name":"stdout","text":"batch: 89 / 345, vectors: 8900000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"305707a827dd4ed3a31561ed30da7b22"}},"metadata":{}},{"name":"stdout","text":"batch: 90 / 345, vectors: 9000000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2048ed734853483faeb4dfde3a090a97"}},"metadata":{}},{"name":"stdout","text":"batch: 91 / 345, vectors: 9100000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9346e93208e46e5b78a89b9d06b843d"}},"metadata":{}},{"name":"stdout","text":"batch: 92 / 345, vectors: 9200000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12b12aa59004444d83d27ce7264ba034"}},"metadata":{}},{"name":"stdout","text":"batch: 93 / 345, vectors: 9300000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57e108fa73354ef8abe6426e27fe589c"}},"metadata":{}},{"name":"stdout","text":"batch: 94 / 345, vectors: 9400000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8a7aa67c75c4c2890f2ceaf392bff38"}},"metadata":{}},{"name":"stdout","text":"batch: 95 / 345, vectors: 9500000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d98cff48f2747e6bee09f9f50fb0c6f"}},"metadata":{}},{"name":"stdout","text":"batch: 96 / 345, vectors: 9600000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"960944e59522412fa8d0cc713b5832be"}},"metadata":{}},{"name":"stdout","text":"batch: 97 / 345, vectors: 9700000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87dc606c3b6f4b19b4ca5ef41ae6989a"}},"metadata":{}},{"name":"stdout","text":"batch: 98 / 345, vectors: 9800000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02086e36da53462c8852bc7ed538fe16"}},"metadata":{}},{"name":"stdout","text":"batch: 99 / 345, vectors: 9900000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b6732a084f445f92cbfb8dc39987cc"}},"metadata":{}},{"name":"stdout","text":"batch: 100 / 345, vectors: 10000000\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls -l","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:38:47.630823Z","iopub.execute_input":"2023-11-24T05:38:47.631224Z","iopub.status.idle":"2023-11-24T05:38:48.819853Z","shell.execute_reply.started":"2023-11-24T05:38:47.631189Z","shell.execute_reply":"2023-11-24T05:38:48.818851Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"total 156688\n-rw-r--r-- 1 root root 160445268 Nov 24 05:38 candidates.index\n","output_type":"stream"}]},{"cell_type":"code","source":"# rm -rf candidates.index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}